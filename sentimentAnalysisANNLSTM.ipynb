{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Important Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for reaed data\n",
    "import re #for text cleansing\n",
    "\n",
    "from nltk.corpus import stopwords #for clean stopwords\n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "#save model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saya tadinya penasaran dengan tempat ini karen...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kang , jalan di muararajeun baru , baru sebula...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>melihat itu kader demokrat ribut dengan pak hn...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tak usah nonton film itu , bahasa jawa semua ....</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ini si monyet bawah gua , nama nya saja anonim...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  saya tadinya penasaran dengan tempat ini karen...  negative\n",
       "1  kang , jalan di muararajeun baru , baru sebula...  negative\n",
       "2  melihat itu kader demokrat ribut dengan pak hn...  negative\n",
       "3  tak usah nonton film itu , bahasa jawa semua ....  negative\n",
       "4  ini si monyet bawah gua , nama nya saja anonim...  negative"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfText = pd.read_csv('dataset/train_preprocess_-_BALANCE.tsv', sep='\\t', names=['text', 'label'])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15162</th>\n",
       "      <td>mendikbud</td>\n",
       "      <td>menteri pendidikan dan kebudayaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15163</th>\n",
       "      <td>mendag</td>\n",
       "      <td>menteri perdagangan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15164</th>\n",
       "      <td>menaker</td>\n",
       "      <td>menteri tenaga kerja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15165</th>\n",
       "      <td>memetwit</td>\n",
       "      <td>mentwit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15166</th>\n",
       "      <td>megangin</td>\n",
       "      <td>memegang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  original                        replacement\n",
       "0      anakjakartaasikasik           anak jakarta asyik asyik\n",
       "1             pakcikdahtua                  pak cik sudah tua\n",
       "2           pakcikmudalagi                  pak cik muda lagi\n",
       "3              t3tapjokowi                       tetap jokowi\n",
       "4                       3x                          tiga kali\n",
       "...                    ...                                ...\n",
       "15162            mendikbud  menteri pendidikan dan kebudayaan\n",
       "15163               mendag                menteri perdagangan\n",
       "15164              menaker               menteri tenaga kerja\n",
       "15165             memetwit                            mentwit\n",
       "15166             megangin                           memegang\n",
       "\n",
       "[15167 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAlay = pd.read_csv('dataset/new_kamusalay.csv', encoding='latin-1', names=['original', 'replacement'])\n",
    "dfAlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>wong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>yaitu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>yakin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>yakni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>yang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>787 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stopword\n",
       "0        gue\n",
       "1        gua\n",
       "2         ya\n",
       "3         yg\n",
       "4         ga\n",
       "..       ...\n",
       "782     wong\n",
       "783    yaitu\n",
       "784    yakin\n",
       "785    yakni\n",
       "786     yang\n",
       "\n",
       "[787 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfStopWord = pd.read_csv('dataset/stopwordbahasa.csv', names=['stopword'])\n",
    "dfStopWord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleansing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove kata alay\n",
    "def normalize_alay(text):\n",
    "    alay_dict_map = dict(zip(dfAlay['original'], dfAlay['replacement']))\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ',text)\n",
    "\n",
    "# remove stopword\n",
    "def remove_stopword(text):\n",
    "    stopword_list = set(stopwords.words('indonesian'))\n",
    "    return ' '.join([word for word in text.split(' ') if word not in stopword_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = normalize_alay(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stopword(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>penasaran nya foto foto kunjungan artis pas pe...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kang   jalan muararajeun   sebulanan dibenarka...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kader demokrat ribut hnw partai keadilan sejah...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menonton film   bahasa jawa   mengerti   teks ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sih monyet gue   nama nya anonim pengecut paka...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>mereka mempertahankan spesifikasi dasar model ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>mereka mempertahankan kejuaraan  memenangkan k...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>mereka mempertahankan gelar juara 2016  mengal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>mereka mempertahankan kemerdekaan administrati...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>mereka mempertahankan keanggotaan movie tome t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "0      penasaran nya foto foto kunjungan artis pas pe...  negative\n",
       "1      kang   jalan muararajeun   sebulanan dibenarka...  negative\n",
       "2      kader demokrat ribut hnw partai keadilan sejah...  negative\n",
       "3      menonton film   bahasa jawa   mengerti   teks ...  negative\n",
       "4      sih monyet gue   nama nya anonim pengecut paka...  negative\n",
       "...                                                  ...       ...\n",
       "10195  mereka mempertahankan spesifikasi dasar model ...   neutral\n",
       "10196  mereka mempertahankan kejuaraan  memenangkan k...   neutral\n",
       "10197  mereka mempertahankan gelar juara 2016  mengal...   neutral\n",
       "10198  mereka mempertahankan kemerdekaan administrati...   neutral\n",
       "10199  mereka mempertahankan keanggotaan movie tome t...   neutral\n",
       "\n",
       "[10200 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfText['text'] = dfText['text'].apply(preprocess)\n",
    "dfText['text'] = dfText['text'].str.lower()\n",
    "dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        2\n",
       "2        2\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "10195    0\n",
       "10196    0\n",
       "10197    0\n",
       "10198    0\n",
       "10199    0\n",
       "Name: label, Length: 10200, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictLabel = {'neutral' : 0, 'positive' : 1, 'negative' : 2}\n",
    "dfText['label'] = dfText['label'].map(dictLabel)\n",
    "dfText['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Info Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10200"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10200 entries, 0 to 10199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10200 non-null  object\n",
      " 1   label   10200 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 159.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfText.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfText.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-idf Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(dfText['text'])\n",
    "X_train_counts.shape\n",
    "\n",
    "with open('models/count_vect.pkl', 'wb') as f:\n",
    "    pickle.dump(count_vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tranformer =TfidfTransformer(smooth_idf=True,use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_tranformer.transform(X_train_counts).toarray()\n",
    "X_train_tf.shape\n",
    "\n",
    "with open('models/tf_tranformer.pkl', 'wb') as f:\n",
    "    pickle.dump(tf_tranformer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Change Label to Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrayLabel = dfText['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(arrayLabel, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10200"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10200, 200)\n"
     ]
    }
   ],
   "source": [
    "max_words = 10200\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(dfText['text'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(dfText['text'])\n",
    "text = pad_sequences(sequences, maxlen=max_len)\n",
    "print(text.shape)\n",
    "\n",
    "with open('models/tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam   \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7650 2550 7650 2550\n"
     ]
    }
   ],
   "source": [
    "# split tfidftransformers data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_transf, X_test_transf, y_train_transf, y_test_transf = train_test_split(X_train_tf,labels, random_state=0)\n",
    "print(len(X_train_transf),len(X_test_transf),len(y_train_transf),len(y_test_transf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7650 2550 7650 2550\n"
     ]
    }
   ],
   "source": [
    "# split tokenization data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_token, X_test_token, y_train_token, y_test_token = train_test_split(text,labels, random_state=0)\n",
    "print(len(X_train_token),len(X_test_token),len(y_train_token),len(y_test_token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.8267 - accuracy: 0.6230\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75686, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 19s 68ms/step - loss: 0.8267 - accuracy: 0.6230 - val_loss: 0.6256 - val_accuracy: 0.7569\n",
      "Epoch 2/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.4998 - accuracy: 0.8182\n",
      "Epoch 2: val_accuracy improved from 0.75686 to 0.81412, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.4998 - accuracy: 0.8182 - val_loss: 0.4772 - val_accuracy: 0.8141\n",
      "Epoch 3/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.8647\n",
      "Epoch 3: val_accuracy improved from 0.81412 to 0.84118, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.3852 - accuracy: 0.8647 - val_loss: 0.4181 - val_accuracy: 0.8412\n",
      "Epoch 4/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.8918\n",
      "Epoch 4: val_accuracy improved from 0.84118 to 0.85529, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.3034 - accuracy: 0.8918 - val_loss: 0.3817 - val_accuracy: 0.8553\n",
      "Epoch 5/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.9174\n",
      "Epoch 5: val_accuracy improved from 0.85529 to 0.86471, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.2360 - accuracy: 0.9174 - val_loss: 0.3698 - val_accuracy: 0.8647\n",
      "Epoch 6/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.9335\n",
      "Epoch 6: val_accuracy improved from 0.86471 to 0.86588, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.1908 - accuracy: 0.9335 - val_loss: 0.3875 - val_accuracy: 0.8659\n",
      "Epoch 7/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.1554 - accuracy: 0.9464\n",
      "Epoch 7: val_accuracy improved from 0.86588 to 0.86667, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.1553 - accuracy: 0.9464 - val_loss: 0.3795 - val_accuracy: 0.8667\n",
      "Epoch 8/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.1285 - accuracy: 0.9544\n",
      "Epoch 8: val_accuracy improved from 0.86667 to 0.86902, saving model to best_model1.hdf5\n",
      "240/240 [==============================] - 11s 47ms/step - loss: 0.1285 - accuracy: 0.9544 - val_loss: 0.4011 - val_accuracy: 0.8690\n",
      "Epoch 9/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.9608\n",
      "Epoch 9: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 18s 74ms/step - loss: 0.1096 - accuracy: 0.9608 - val_loss: 0.4205 - val_accuracy: 0.8682\n",
      "Epoch 10/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9664\n",
      "Epoch 10: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 19s 80ms/step - loss: 0.0965 - accuracy: 0.9664 - val_loss: 0.4598 - val_accuracy: 0.8639\n",
      "Epoch 11/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.9710\n",
      "Epoch 11: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0817 - accuracy: 0.9710 - val_loss: 0.4915 - val_accuracy: 0.8620\n",
      "Epoch 12/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.9722\n",
      "Epoch 12: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.0793 - accuracy: 0.9722 - val_loss: 0.5022 - val_accuracy: 0.8604\n",
      "Epoch 13/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0660 - accuracy: 0.9774\n",
      "Epoch 13: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.0660 - accuracy: 0.9774 - val_loss: 0.5421 - val_accuracy: 0.8620\n",
      "Epoch 14/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0619 - accuracy: 0.9761\n",
      "Epoch 14: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0620 - accuracy: 0.9761 - val_loss: 0.5459 - val_accuracy: 0.8596\n",
      "Epoch 15/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0556 - accuracy: 0.9797\n",
      "Epoch 15: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0556 - accuracy: 0.9797 - val_loss: 0.5672 - val_accuracy: 0.8604\n",
      "Epoch 16/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9805\n",
      "Epoch 16: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.0493 - accuracy: 0.9805 - val_loss: 0.6294 - val_accuracy: 0.8549\n",
      "Epoch 17/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.9790\n",
      "Epoch 17: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 48ms/step - loss: 0.0547 - accuracy: 0.9790 - val_loss: 0.6114 - val_accuracy: 0.8576\n",
      "Epoch 18/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0474 - accuracy: 0.9829\n",
      "Epoch 18: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.0474 - accuracy: 0.9829 - val_loss: 0.6336 - val_accuracy: 0.8478\n",
      "Epoch 19/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9817\n",
      "Epoch 19: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.0494 - accuracy: 0.9817 - val_loss: 0.6046 - val_accuracy: 0.8533\n",
      "Epoch 20/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.9830\n",
      "Epoch 20: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.0429 - accuracy: 0.9830 - val_loss: 0.6646 - val_accuracy: 0.8518\n",
      "Epoch 21/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0397 - accuracy: 0.9833\n",
      "Epoch 21: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0397 - accuracy: 0.9833 - val_loss: 0.6366 - val_accuracy: 0.8498\n",
      "Epoch 22/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0401 - accuracy: 0.9857\n",
      "Epoch 22: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 52ms/step - loss: 0.0401 - accuracy: 0.9858 - val_loss: 0.6764 - val_accuracy: 0.8580\n",
      "Epoch 23/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9852\n",
      "Epoch 23: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.0365 - accuracy: 0.9852 - val_loss: 0.6989 - val_accuracy: 0.8592\n",
      "Epoch 24/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 0.9842\n",
      "Epoch 24: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 23s 96ms/step - loss: 0.0373 - accuracy: 0.9842 - val_loss: 0.6631 - val_accuracy: 0.8580\n",
      "Epoch 25/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9852\n",
      "Epoch 25: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0383 - accuracy: 0.9852 - val_loss: 0.7121 - val_accuracy: 0.8569\n",
      "Epoch 26/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9844\n",
      "Epoch 26: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 17s 73ms/step - loss: 0.0362 - accuracy: 0.9844 - val_loss: 0.7314 - val_accuracy: 0.8545\n",
      "Epoch 27/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9865\n",
      "Epoch 27: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.0338 - accuracy: 0.9865 - val_loss: 0.7189 - val_accuracy: 0.8553\n",
      "Epoch 28/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9880\n",
      "Epoch 28: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.0291 - accuracy: 0.9880 - val_loss: 0.7756 - val_accuracy: 0.8537\n",
      "Epoch 29/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9865\n",
      "Epoch 29: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 56ms/step - loss: 0.0336 - accuracy: 0.9865 - val_loss: 0.7218 - val_accuracy: 0.8565\n",
      "Epoch 30/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9889\n",
      "Epoch 30: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0293 - accuracy: 0.9889 - val_loss: 0.7347 - val_accuracy: 0.8557\n",
      "Epoch 31/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9868\n",
      "Epoch 31: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0285 - accuracy: 0.9868 - val_loss: 0.7808 - val_accuracy: 0.8529\n",
      "Epoch 32/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9873\n",
      "Epoch 32: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0337 - accuracy: 0.9873 - val_loss: 0.7894 - val_accuracy: 0.8522\n",
      "Epoch 33/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9890\n",
      "Epoch 33: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0272 - accuracy: 0.9890 - val_loss: 0.7950 - val_accuracy: 0.8482\n",
      "Epoch 34/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9884\n",
      "Epoch 34: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0257 - accuracy: 0.9884 - val_loss: 0.8151 - val_accuracy: 0.8514\n",
      "Epoch 35/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0278 - accuracy: 0.9882\n",
      "Epoch 35: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0278 - accuracy: 0.9882 - val_loss: 0.7689 - val_accuracy: 0.8463\n",
      "Epoch 36/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9871\n",
      "Epoch 36: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0291 - accuracy: 0.9871 - val_loss: 0.8090 - val_accuracy: 0.8545\n",
      "Epoch 37/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9881\n",
      "Epoch 37: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 50ms/step - loss: 0.0247 - accuracy: 0.9881 - val_loss: 0.8346 - val_accuracy: 0.8522\n",
      "Epoch 38/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9880\n",
      "Epoch 38: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0276 - accuracy: 0.9880 - val_loss: 0.7823 - val_accuracy: 0.8510\n",
      "Epoch 39/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9878\n",
      "Epoch 39: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0285 - accuracy: 0.9878 - val_loss: 0.7857 - val_accuracy: 0.8557\n",
      "Epoch 40/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9905\n",
      "Epoch 40: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 54ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 0.8052 - val_accuracy: 0.8584\n",
      "Epoch 41/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9890\n",
      "Epoch 41: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 0.8137 - val_accuracy: 0.8545\n",
      "Epoch 42/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.9903\n",
      "Epoch 42: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 18s 73ms/step - loss: 0.0239 - accuracy: 0.9903 - val_loss: 0.8871 - val_accuracy: 0.8529\n",
      "Epoch 43/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9891\n",
      "Epoch 43: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 62ms/step - loss: 0.0261 - accuracy: 0.9892 - val_loss: 0.8084 - val_accuracy: 0.8510\n",
      "Epoch 44/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9903\n",
      "Epoch 44: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 0.8617 - val_accuracy: 0.8498\n",
      "Epoch 45/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9906\n",
      "Epoch 45: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 17s 72ms/step - loss: 0.0210 - accuracy: 0.9906 - val_loss: 0.8717 - val_accuracy: 0.8569\n",
      "Epoch 46/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 0.9885\n",
      "Epoch 46: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0248 - accuracy: 0.9885 - val_loss: 0.8122 - val_accuracy: 0.8510\n",
      "Epoch 47/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9888\n",
      "Epoch 47: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 16s 67ms/step - loss: 0.0236 - accuracy: 0.9888 - val_loss: 0.8665 - val_accuracy: 0.8494\n",
      "Epoch 48/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9894\n",
      "Epoch 48: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 58ms/step - loss: 0.0232 - accuracy: 0.9894 - val_loss: 0.8798 - val_accuracy: 0.8522\n",
      "Epoch 49/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9902\n",
      "Epoch 49: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 17s 71ms/step - loss: 0.0212 - accuracy: 0.9902 - val_loss: 0.8655 - val_accuracy: 0.8533\n",
      "Epoch 50/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 0.9889\n",
      "Epoch 50: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 64ms/step - loss: 0.0252 - accuracy: 0.9889 - val_loss: 0.8274 - val_accuracy: 0.8522\n",
      "Epoch 51/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9905\n",
      "Epoch 51: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 16s 66ms/step - loss: 0.0202 - accuracy: 0.9905 - val_loss: 0.8233 - val_accuracy: 0.8514\n",
      "Epoch 52/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9902\n",
      "Epoch 52: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.0223 - accuracy: 0.9902 - val_loss: 0.8625 - val_accuracy: 0.8471\n",
      "Epoch 53/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9903\n",
      "Epoch 53: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.0210 - accuracy: 0.9903 - val_loss: 0.8519 - val_accuracy: 0.8490\n",
      "Epoch 54/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9899\n",
      "Epoch 54: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 61ms/step - loss: 0.0212 - accuracy: 0.9899 - val_loss: 0.8441 - val_accuracy: 0.8490\n",
      "Epoch 55/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9910\n",
      "Epoch 55: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 56ms/step - loss: 0.0219 - accuracy: 0.9910 - val_loss: 0.9079 - val_accuracy: 0.8498\n",
      "Epoch 56/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9893\n",
      "Epoch 56: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 59ms/step - loss: 0.0233 - accuracy: 0.9893 - val_loss: 0.8759 - val_accuracy: 0.8459\n",
      "Epoch 57/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9897\n",
      "Epoch 57: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0228 - accuracy: 0.9897 - val_loss: 0.8627 - val_accuracy: 0.8510\n",
      "Epoch 58/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9905\n",
      "Epoch 58: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0205 - accuracy: 0.9905 - val_loss: 0.8966 - val_accuracy: 0.8482\n",
      "Epoch 59/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9888\n",
      "Epoch 59: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0198 - accuracy: 0.9888 - val_loss: 0.8870 - val_accuracy: 0.8525\n",
      "Epoch 60/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9919\n",
      "Epoch 60: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0177 - accuracy: 0.9919 - val_loss: 0.9216 - val_accuracy: 0.8518\n",
      "Epoch 61/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9907\n",
      "Epoch 61: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0211 - accuracy: 0.9907 - val_loss: 0.8570 - val_accuracy: 0.8518\n",
      "Epoch 62/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9895\n",
      "Epoch 62: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.0209 - accuracy: 0.9895 - val_loss: 0.8899 - val_accuracy: 0.8475\n",
      "Epoch 63/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9907\n",
      "Epoch 63: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 22s 91ms/step - loss: 0.0200 - accuracy: 0.9907 - val_loss: 0.8672 - val_accuracy: 0.8478\n",
      "Epoch 64/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9908\n",
      "Epoch 64: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 57ms/step - loss: 0.0201 - accuracy: 0.9908 - val_loss: 0.9071 - val_accuracy: 0.8467\n",
      "Epoch 65/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9903\n",
      "Epoch 65: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 55ms/step - loss: 0.0207 - accuracy: 0.9903 - val_loss: 0.9108 - val_accuracy: 0.8475\n",
      "Epoch 66/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9910\n",
      "Epoch 66: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 15s 63ms/step - loss: 0.0200 - accuracy: 0.9910 - val_loss: 0.9202 - val_accuracy: 0.8482\n",
      "Epoch 67/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9890\n",
      "Epoch 67: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 14s 60ms/step - loss: 0.0219 - accuracy: 0.9890 - val_loss: 0.8857 - val_accuracy: 0.8455\n",
      "Epoch 68/70\n",
      "240/240 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9910\n",
      "Epoch 68: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 13s 53ms/step - loss: 0.0186 - accuracy: 0.9910 - val_loss: 0.9323 - val_accuracy: 0.8482\n",
      "Epoch 69/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9914\n",
      "Epoch 69: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 51ms/step - loss: 0.0192 - accuracy: 0.9914 - val_loss: 0.9132 - val_accuracy: 0.8475\n",
      "Epoch 70/70\n",
      "239/240 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9899\n",
      "Epoch 70: val_accuracy did not improve from 0.86902\n",
      "240/240 [==============================] - 12s 49ms/step - loss: 0.0197 - accuracy: 0.9899 - val_loss: 0.9341 - val_accuracy: 0.8478\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "model1.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train_token, y_train_token, epochs=70,validation_data=(X_test_token, y_test_token),callbacks=[checkpoint1])\n",
    "model1.save('models/LSTMmodel.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.94635042\n",
      "Validation score: 0.454902\n",
      "Iteration 2, loss = 0.96195108\n",
      "Validation score: 0.840523\n",
      "Iteration 3, loss = 0.31333463\n",
      "Validation score: 0.852288\n",
      "Iteration 4, loss = 0.13787652\n",
      "Validation score: 0.847059\n",
      "Iteration 5, loss = 0.08077823\n",
      "Validation score: 0.837908\n",
      "Iteration 6, loss = 0.05662197\n",
      "Validation score: 0.832680\n",
      "Iteration 7, loss = 0.04618218\n",
      "Validation score: 0.847059\n",
      "Iteration 8, loss = 0.03764150\n",
      "Validation score: 0.824837\n",
      "Iteration 9, loss = 0.03639285\n",
      "Validation score: 0.836601\n",
      "Iteration 10, loss = 0.03694461\n",
      "Validation score: 0.836601\n",
      "Iteration 11, loss = 0.03570344\n",
      "Validation score: 0.832680\n",
      "Iteration 12, loss = 0.03162549\n",
      "Validation score: 0.833987\n",
      "Iteration 13, loss = 0.02976242\n",
      "Validation score: 0.831373\n",
      "Iteration 14, loss = 0.02850119\n",
      "Validation score: 0.831373\n",
      "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(256,128,64,32), activation=\"relu\",random_state=1, solver='adam', alpha=1e-5, early_stopping=True, max_iter=1000, verbose=True)\n",
    "clf.fit(X_train_transf,y_train_transf)\n",
    "\n",
    "pkl_filename = \"models/ANNmodel.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(clf, file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_test_transf)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"models/LSTMmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 2s - loss: 0.3560 - accuracy: 0.8843 - 2s/epoch - 29ms/step\n",
      "Model accuracy:  0.884313702583313\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test_token, y_test_token, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 3s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test_token.argmax(axis=1), np.around(predictions, decimals=0).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ansha\\AppData\\Local\\Temp/ipykernel_21808/3444368053.py:3: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame(matrix, index = ['Neutral','Negative','Positive'],columns = ['Neutral','Negative','Positive'])\n",
    "#Normalizing\n",
    "conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize = (15,15))\n",
    "sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['neutral', 'positive', 'negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['makanan disini enak banget dan harga nya murah murah'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "label[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914640522875817"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(y_pred == y_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       881\n",
      "           1       0.86      0.86      0.86       839\n",
      "           2       0.84      0.80      0.82       830\n",
      "\n",
      "   micro avg       0.88      0.86      0.87      2550\n",
      "   macro avg       0.88      0.86      0.87      2550\n",
      "weighted avg       0.88      0.86      0.87      2550\n",
      " samples avg       0.85      0.86      0.86      2550\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_transf, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "binar-platinum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db4ff88cc76be81058deeb6a297d780e9952340fc8904a6fb17d0c57853df088"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
